<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>WebAR SLAM Starter</title>
  <style>
    html, body { margin: 0; padding: 0; overflow: hidden; background: black; }
    canvas { position: absolute; top: 0; left: 0; }
  </style>
</head>
<body>
  <video id="videoElement" autoplay playsinline style="display: none;"></video>
  <canvas id="videoCanvas"></canvas>
  <canvas id="threeCanvas"></canvas>

  <script src="https://cdn.jsdelivr.net/npm/three@0.161.0/build/three.min.js"></script>
  <script async src="https://docs.opencv.org/4.x/opencv.js" type="text/javascript"></script>

  <script>
    const video = document.getElementById('videoElement');
    const videoCanvas = document.getElementById('videoCanvas');
    const threeCanvas = document.getElementById('threeCanvas');
    const ctx = videoCanvas.getContext('2d');

    let streaming = false;

    // Set up Three.js
    const scene = new THREE.Scene();
    const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.01, 100);
    camera.position.z = 1;

    const renderer = new THREE.WebGLRenderer({ canvas: threeCanvas, alpha: true });
    renderer.setSize(window.innerWidth, window.innerHeight);

    const cube = new THREE.Mesh(
      new THREE.BoxGeometry(0.2, 0.2, 0.2),
      new THREE.MeshNormalMaterial()
    );
    scene.add(cube);

    function animate() {
      requestAnimationFrame(animate);
      cube.rotation.x += 0.01;
      cube.rotation.y += 0.01;
      renderer.render(scene, camera);
    }

    function startVideoStream() {
      navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' }, audio: false })
        .then((stream) => {
          video.srcObject = stream;
          video.play();
        })
        .catch((err) => {
          console.error("Error accessing the camera: ", err);
        });
    }

    function init() {
      if (video.readyState >= 2 && !streaming) {
        streaming = true;
        videoCanvas.width = threeCanvas.width = video.videoWidth;
        videoCanvas.height = threeCanvas.height = video.videoHeight;
        animate();
        processVideo();
      } else {
        requestAnimationFrame(init);
      }
    }

    function processVideo() {
      if (typeof cv === 'undefined') {
        console.log("Waiting for OpenCV.js to load...");
        requestAnimationFrame(processVideo);
        return;
      }

      try {
        ctx.drawImage(video, 0, 0, videoCanvas.width, videoCanvas.height);
        const src = cv.imread(videoCanvas);
        const gray = new cv.Mat();
        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

        const orb = new cv.ORB();
        const keypoints = new cv.KeyPointVector();
        orb.detect(gray, keypoints);

        for (let i = 0; i < keypoints.size(); i++) {
          let pt = keypoints.get(i).pt;
          ctx.beginPath();
          ctx.arc(pt.x, pt.y, 3, 0, 2 * Math.PI);
          ctx.fillStyle = 'red';
          ctx.fill();
        }

        src.delete();
        gray.delete();
        orb.delete();
        keypoints.delete();
      } catch (err) {
        console.error("OpenCV error:", err);
      }

      requestAnimationFrame(processVideo);
    }

    // Start everything
    startVideoStream();
    init();
  </script>
</body>
</html>
